{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings\n",
    "\n",
    "The function `get_embedding` will give us an embedding for an input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,        # altered by me\n",
    "    chart_from_components,\n",
    "    chart_from_components_3D,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")   # note that some of the functions in embeddings_utils.py are NOT imported here\n",
    "    # for example the intriguing plot_multiclass_precision_recall - what does that do?\n",
    "\n",
    "# does this method mean that '.env' can contain multiple values provided we keep track of which is which and only select the ones we want?\n",
    "# yes, but to be used with great care; here we ignore the possibility\n",
    "for k in dotenv.dotenv_values():\n",
    "    openai.api_key=k\n",
    "\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7fb7c05c6220 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/embeddings_utils.py:23\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m     21\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text], engine\u001b[39m=\u001b[39;49mengine)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: <empty message>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m text1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhatsoever proceeds from the gods immediately, that any man will grant totally depends from their divine providence. As for those things that are commonly said to happen by fortune, even those must be conceived to have dependence from nature, or from that first and general connection, and concatenation of all those things, which more apparently by the divine providence are administered and brought to pass. All things flow from thence: and whatsoever it is that is, is both necessary, and conducing to the whole (part of which thou art), and whatsoever it is that is requisite and necessary for the preservation of the general, must of necessity for every particular nature, be good and behoveful.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m# note that get_embedding expects TEXT and MODEL not prompt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result1 \u001b[39m=\u001b[39m get_embedding(\n\u001b[1;32m      5\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-embedding-ada-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     text\u001b[39m=\u001b[39;49mtext1,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39m# in this case the API merely returns the embedding with nothing additional (apparently)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m element\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/openai-store/env/lib/python3.9/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7fb7c05c6220 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "text1 = \"Whatsoever proceeds from the gods immediately, that any man will grant totally depends from their divine providence. As for those things that are commonly said to happen by fortune, even those must be conceived to have dependence from nature, or from that first and general connection, and concatenation of all those things, which more apparently by the divine providence are administered and brought to pass. All things flow from thence: and whatsoever it is that is, is both necessary, and conducing to the whole (part of which thou art), and whatsoever it is that is requisite and necessary for the preservation of the general, must of necessity for every particular nature, be good and behoveful.\"\n",
    "\n",
    "# note that get_embedding expects TEXT and MODEL not prompt\n",
    "result1 = get_embedding(\n",
    "    engine=\"text-embedding-ada-002\",\n",
    "    text=text1,\n",
    ")\n",
    "# in this case the API merely returns the embedding with nothing additional (apparently)\n",
    "element=10\n",
    "print(f\"First {element} terms of embedding returned = {result1[:element]}\")\n",
    "len(f\"Length of embedding returned = {result1}\")\n",
    "\n",
    "text2 = \"Whatsoever proceeds from john puddefoot immediately, that any man will grant totally depends from their earthly providence. As for those things that are commonly said to happen by fortune, even those must be conceived to have dependence from nature, or from that first and general connection, and concatenation of all those things, which more apparently by the divine providence are administered and brought to pass. All things flow from thence: and whatsoever it is that is, is both necessary, and conducing to the whole (part of which thou art), and whatsoever it is that is requisite and necessary for the preservation of the general, must of necessity for every particular nature, be good and behoveful.\"\n",
    "\n",
    "result2 = get_embedding(\n",
    "    engine=\"text-embedding-ada-002\",\n",
    "    text=text2,\n",
    ")\n",
    "# in this case the API merely returns the embedding with nothing additional (apparently)\n",
    "print(f\"First {element} terms of embedding returned = {result2[:element]}\")\n",
    "len(f\"Length of embedding returned = {result2}\")\n",
    "\n",
    "text3 = \"X. It is the part of a man endowed with a good understanding faculty, to consider what they themselves are in very deed, from whose bare conceits and voices, honour and credit do proceed: as also what it is to die, and how if a man shall consider this by itself alone, to die, and separate from it in his mind all those things which with it usually represent themselves unto us, he can conceive of it no otherwise, than as of a work of nature, and he that fears any work of nature, is a very child. Now death, it is not only a work of nature, but also conducing to nature.\"\n",
    "\n",
    "result3 = get_embedding(\n",
    "    engine=\"text-embedding-ada-002\",\n",
    "    text=text3,\n",
    ")\n",
    "# in this case the API merely returns the embedding with nothing additional (apparently)\n",
    "# but what does it return if the input text exceeds the 8192 maximum length?\n",
    "print(f\"First {element} terms of embedding returned = {result3[:element]}\")\n",
    "\n",
    "text4 = \"As he that throws a stone at thee, aims only to do thee a hurt; so he that deals with thee in this manner, aims only at thy hurt, and to no other end; wherefore then should it be grievous unto thee? For he doth no more than thou dost hourly unto others. Again; that stone is without understanding, and superfluously doth hurt: but he that deals with thee contemptuously, is one that is both wicked by nature, and superfluously doth hurt. Again; that stone desiring to break thy skull, if either it cannot, or thou prevent it not, it will not be turned back from its violent nature, (for to a stone, it is a natural thing to break the skull of man) but will proceed on to what it would, but in a more troublesome way: but he that deals contemptuously with thee, will be more grievously irritated, if he be not revenged, than before he was angered. Again; that stone that flies at thee out of the hand of him that throws it, had it understanding, would either forbear, or would not fly at thee. But to him that contemneth thee, it is a grievous thing, that he cannot revenge.\"\n",
    "\n",
    "result4 = get_embedding(\n",
    "    engine=\"text-embedding-ada-002\",\n",
    "    text=text4,\n",
    ")\n",
    "# in this case the API merely returns the embedding with nothing additional (apparently)\n",
    "# but what does it return if the input text exceeds the 8192 maximum length?\n",
    "print(f\"First {element} terms of embedding returned = {result4[:element]}\")\n",
    "\n",
    "text5 = \"If we perform a tensor outer product on two [2,2] tensors we obtain as [2,2,2,2] tensor with four dimensions/axes that cannot be represented easily. So if we then do a tf.reduce_sum on the elements we find that we get answers that seem not to have a clear geometrical relationship with those they come from, and this is because the relationship is four-dimensional, not three. And operation like reduce_sum that collapses a 4D tensor into a 3D tensor can obviously do so in a number of ways; four ways, in fact, each of which produces a different 3D tensor depending on the “direction” in which the collapse is applied. Since each dimension of the 4D tensor is a 3D tensor, this is exactly what we would expect.\"\n",
    "\n",
    "result5 = get_embedding(\n",
    "    engine=\"text-embedding-ada-002\",\n",
    "    text=text5,\n",
    ")\n",
    "# in this case the API merely returns the embedding with nothing additional (apparently)\n",
    "# but what does it return if the input text exceeds the 8192 maximum length?\n",
    "print(f\"First {element} terms of embedding returned = {result5[:element]}\")\n",
    "\n",
    "print(\"Regardless of the length of the input - up to 8192 tokens - the embedding length is 1536.\")\n",
    "print(f\"Length of text1 = {len(text1):4.0f}; length of embedding returned = {len(result1)}\")\n",
    "print(f\"Length of text2 = {len(text2):4.0f}; length of embedding returned = {len(result2)}\")\n",
    "print(f\"Length of text3 = {len(text3):4.0f}; length of embedding returned = {len(result3)}\")\n",
    "print(f\"Length of text4 = {len(text4):4.0f}; length of embedding returned = {len(result4)}\")\n",
    "print(f\"Length of text5 = {len(text5):4.0f}; length of embedding returned = {len(result5)}\")\n",
    "\n",
    "# I am also puzzled by why this is called a COSINE distance when it is really a SINE distance\n",
    "dfe=distances_from_embeddings(result1,[result1,result2,result3,result4,result5])\n",
    "\n",
    "print(\"Note that the first three are original; the fourth from WMMS; the fifth from JCP:\\n\",dfe,'\\n',np.arccos([dfe]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
